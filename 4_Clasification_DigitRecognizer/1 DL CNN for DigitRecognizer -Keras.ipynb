{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 1 DL CNN for DigitRecognizer -Keras.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "LgcAAVmXgBPm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt, matplotlib.image as mpimg\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EITzxKZRgBPy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import losses,optimizers,metrics\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4PihLjAggBP1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "metadata": {
        "id": "cra90fdEsmsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "144cc8aa-454c-4922-a6b7-fc153f2327c6"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K58DeQH2gBP2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labeled_images = pd.read_csv('gdrive/My Drive/dataML/train.csv')\n",
        "#labeled_images = pd.read_csv('train.csv')\n",
        "images = labeled_images.iloc[:,1:]\n",
        "labels = labeled_images.iloc[:,:1]\n",
        "train_images, test_images,train_labels, test_labels = train_test_split(images, labels, test_size=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "At9soAW0qOs4",
        "colab_type": "code",
        "outputId": "d9be30a6-27bd-4eb2-d35c-97d2b059703e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41580, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "UfkBgDM1gBP5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### convert the data to the right type"
      ]
    },
    {
      "metadata": {
        "id": "-X3Uu-o_gBP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = train_images.values.reshape(train_images.shape[0],28,28,1)\n",
        "x_test = test_images.values.reshape(test_images.shape[0],28,28,1)\n",
        "y_train = train_labels.values\n",
        "y_test = test_labels.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7vboLIlsgBP9",
        "colab_type": "code",
        "outputId": "30601e9d-113a-4b94-9d12-476184092571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[12].squeeze())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3524acd128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "b6I1adl5gBQD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### convert the data to the right type"
      ]
    },
    {
      "metadata": {
        "id": "GAIvNCv6gBQE",
        "colab_type": "code",
        "outputId": "e5b93688-7225-4701-f767-fd9f61356a13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (41580, 28, 28, 1)\n",
            "41580 train samples\n",
            "420 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "xeMZR7ntgBQI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### convert class vectors to binary class matrices - this is for use in the\n",
        "### categorical_crossentropy loss below"
      ]
    },
    {
      "metadata": {
        "id": "8e2qjHPLgBQJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LT78eGccgBQN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating the Model with Keras\n"
      ]
    },
    {
      "metadata": {
        "id": "TsiSQtSqgBQO",
        "colab_type": "code",
        "outputId": "3127481f-edad-4bd9-ea0f-ace4d20da275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(filters=32,kernel_size=(6,6),strides=(1,1),\n",
        "                        padding=\"same\", \n",
        "                        activation='relu',input_shape=(28,28,1)))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2),padding='same'))\n",
        "model.add(layers.Conv2D(filters=64,kernel_size=(6,6),strides=(1,1),\n",
        "                        padding=\"same\", activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2),padding='same'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(units=1024,activation='relu'))\n",
        "model.add(layers.Dropout(rate=0.5))\n",
        "model.add(layers.Dense(units=10,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 28, 28, 32)        1184      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 14, 14, 64)        73792     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1024)              3212288   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 3,297,514\n",
            "Trainable params: 3,297,514\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BLdOV8vYgBQS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy, \n",
        "              optimizer=keras.optimizers.Adam(0.0001), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pxI5Gi4xgBQV",
        "colab_type": "code",
        "outputId": "98b4a686-7ecd-4038-8f80-9c084256c74f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1754
        }
      },
      "cell_type": "code",
      "source": [
        "H = model.fit(x_train, y_train,\n",
        "          batch_size=100,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 41580 samples, validate on 420 samples\n",
            "Epoch 1/50\n",
            "41580/41580 [==============================] - 9s 218us/sample - loss: 0.4830 - acc: 0.8640 - val_loss: 0.2049 - val_acc: 0.9429\n",
            "Epoch 2/50\n",
            "41580/41580 [==============================] - 8s 201us/sample - loss: 0.1329 - acc: 0.9604 - val_loss: 0.1341 - val_acc: 0.9548\n",
            "Epoch 3/50\n",
            "41580/41580 [==============================] - 8s 201us/sample - loss: 0.0893 - acc: 0.9734 - val_loss: 0.1025 - val_acc: 0.9690\n",
            "Epoch 4/50\n",
            "41580/41580 [==============================] - 8s 200us/sample - loss: 0.0687 - acc: 0.9791 - val_loss: 0.0843 - val_acc: 0.9643\n",
            "Epoch 5/50\n",
            "41580/41580 [==============================] - 8s 202us/sample - loss: 0.0585 - acc: 0.9828 - val_loss: 0.0858 - val_acc: 0.9714\n",
            "Epoch 6/50\n",
            "41580/41580 [==============================] - 8s 200us/sample - loss: 0.0496 - acc: 0.9844 - val_loss: 0.0737 - val_acc: 0.9762\n",
            "Epoch 7/50\n",
            "41580/41580 [==============================] - 8s 201us/sample - loss: 0.0437 - acc: 0.9869 - val_loss: 0.0632 - val_acc: 0.9786\n",
            "Epoch 8/50\n",
            "41580/41580 [==============================] - 8s 202us/sample - loss: 0.0383 - acc: 0.9883 - val_loss: 0.0622 - val_acc: 0.9833\n",
            "Epoch 9/50\n",
            "41580/41580 [==============================] - 8s 201us/sample - loss: 0.0348 - acc: 0.9892 - val_loss: 0.0606 - val_acc: 0.9738\n",
            "Epoch 10/50\n",
            "41580/41580 [==============================] - 8s 201us/sample - loss: 0.0309 - acc: 0.9904 - val_loss: 0.0557 - val_acc: 0.9857\n",
            "Epoch 11/50\n",
            "41580/41580 [==============================] - 8s 201us/sample - loss: 0.0271 - acc: 0.9915 - val_loss: 0.0571 - val_acc: 0.9786\n",
            "Epoch 12/50\n",
            "41580/41580 [==============================] - 8s 200us/sample - loss: 0.0249 - acc: 0.9925 - val_loss: 0.0419 - val_acc: 0.9857\n",
            "Epoch 13/50\n",
            "41580/41580 [==============================] - 8s 202us/sample - loss: 0.0217 - acc: 0.9938 - val_loss: 0.0444 - val_acc: 0.9857\n",
            "Epoch 14/50\n",
            "41580/41580 [==============================] - 9s 207us/sample - loss: 0.0213 - acc: 0.9928 - val_loss: 0.0492 - val_acc: 0.9833\n",
            "Epoch 15/50\n",
            "41580/41580 [==============================] - 9s 205us/sample - loss: 0.0188 - acc: 0.9941 - val_loss: 0.0442 - val_acc: 0.9857\n",
            "Epoch 16/50\n",
            "41580/41580 [==============================] - 8s 201us/sample - loss: 0.0173 - acc: 0.9945 - val_loss: 0.0436 - val_acc: 0.9881\n",
            "Epoch 17/50\n",
            "41580/41580 [==============================] - 9s 207us/sample - loss: 0.0151 - acc: 0.9953 - val_loss: 0.0495 - val_acc: 0.9857\n",
            "Epoch 18/50\n",
            "41580/41580 [==============================] - 8s 204us/sample - loss: 0.0135 - acc: 0.9959 - val_loss: 0.0466 - val_acc: 0.9833\n",
            "Epoch 19/50\n",
            "41580/41580 [==============================] - 8s 202us/sample - loss: 0.0129 - acc: 0.9959 - val_loss: 0.0583 - val_acc: 0.9810\n",
            "Epoch 20/50\n",
            "41580/41580 [==============================] - 9s 205us/sample - loss: 0.0118 - acc: 0.9966 - val_loss: 0.0572 - val_acc: 0.9786\n",
            "Epoch 21/50\n",
            "41580/41580 [==============================] - 9s 212us/sample - loss: 0.0111 - acc: 0.9964 - val_loss: 0.0519 - val_acc: 0.9833\n",
            "Epoch 22/50\n",
            "41580/41580 [==============================] - 9s 209us/sample - loss: 0.0096 - acc: 0.9972 - val_loss: 0.0528 - val_acc: 0.9833\n",
            "Epoch 23/50\n",
            "41580/41580 [==============================] - 9s 217us/sample - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0381 - val_acc: 0.9857\n",
            "Epoch 24/50\n",
            "41580/41580 [==============================] - 9s 212us/sample - loss: 0.0084 - acc: 0.9975 - val_loss: 0.0431 - val_acc: 0.9881\n",
            "Epoch 25/50\n",
            "41580/41580 [==============================] - 9s 214us/sample - loss: 0.0078 - acc: 0.9976 - val_loss: 0.0453 - val_acc: 0.9905\n",
            "Epoch 26/50\n",
            "41580/41580 [==============================] - 9s 211us/sample - loss: 0.0073 - acc: 0.9979 - val_loss: 0.0362 - val_acc: 0.9857\n",
            "Epoch 27/50\n",
            "41580/41580 [==============================] - 9s 215us/sample - loss: 0.0076 - acc: 0.9976 - val_loss: 0.0563 - val_acc: 0.9786\n",
            "Epoch 28/50\n",
            "41580/41580 [==============================] - 9s 215us/sample - loss: 0.0073 - acc: 0.9978 - val_loss: 0.0586 - val_acc: 0.9881\n",
            "Epoch 29/50\n",
            "41580/41580 [==============================] - 9s 216us/sample - loss: 0.0060 - acc: 0.9982 - val_loss: 0.0380 - val_acc: 0.9857\n",
            "Epoch 30/50\n",
            "41580/41580 [==============================] - 9s 216us/sample - loss: 0.0061 - acc: 0.9982 - val_loss: 0.0408 - val_acc: 0.9857\n",
            "Epoch 31/50\n",
            "41580/41580 [==============================] - 10s 229us/sample - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0405 - val_acc: 0.9929\n",
            "Epoch 32/50\n",
            "41580/41580 [==============================] - 9s 223us/sample - loss: 0.0051 - acc: 0.9986 - val_loss: 0.0586 - val_acc: 0.9833\n",
            "Epoch 33/50\n",
            "41580/41580 [==============================] - 9s 226us/sample - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0562 - val_acc: 0.9833\n",
            "Epoch 34/50\n",
            "41580/41580 [==============================] - 10s 231us/sample - loss: 0.0048 - acc: 0.9984 - val_loss: 0.0490 - val_acc: 0.9857\n",
            "Epoch 35/50\n",
            "41580/41580 [==============================] - 9s 226us/sample - loss: 0.0040 - acc: 0.9989 - val_loss: 0.0452 - val_acc: 0.9929\n",
            "Epoch 36/50\n",
            "41580/41580 [==============================] - 9s 228us/sample - loss: 0.0044 - acc: 0.9988 - val_loss: 0.0698 - val_acc: 0.9810\n",
            "Epoch 37/50\n",
            "41580/41580 [==============================] - 9s 224us/sample - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0510 - val_acc: 0.9905\n",
            "Epoch 38/50\n",
            "41580/41580 [==============================] - 9s 226us/sample - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0434 - val_acc: 0.9881\n",
            "Epoch 39/50\n",
            "41580/41580 [==============================] - 9s 222us/sample - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0554 - val_acc: 0.9857\n",
            "Epoch 40/50\n",
            "41580/41580 [==============================] - 9s 221us/sample - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0474 - val_acc: 0.9881\n",
            "Epoch 41/50\n",
            "41580/41580 [==============================] - 9s 219us/sample - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0475 - val_acc: 0.9857\n",
            "Epoch 42/50\n",
            "41580/41580 [==============================] - 9s 221us/sample - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0388 - val_acc: 0.9905\n",
            "Epoch 43/50\n",
            "41580/41580 [==============================] - 9s 218us/sample - loss: 0.0030 - acc: 0.9993 - val_loss: 0.0470 - val_acc: 0.9881\n",
            "Epoch 44/50\n",
            "41580/41580 [==============================] - 9s 216us/sample - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0440 - val_acc: 0.9905\n",
            "Epoch 45/50\n",
            "41580/41580 [==============================] - 9s 217us/sample - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0513 - val_acc: 0.9833\n",
            "Epoch 46/50\n",
            "41580/41580 [==============================] - 9s 216us/sample - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0511 - val_acc: 0.9881\n",
            "Epoch 47/50\n",
            "41580/41580 [==============================] - 9s 217us/sample - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0564 - val_acc: 0.9810\n",
            "Epoch 48/50\n",
            "41580/41580 [==============================] - 9s 220us/sample - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0479 - val_acc: 0.9905\n",
            "Epoch 49/50\n",
            "41580/41580 [==============================] - 9s 221us/sample - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0557 - val_acc: 0.9905\n",
            "Epoch 50/50\n",
            "41580/41580 [==============================] - 9s 218us/sample - loss: 0.0020 - acc: 0.9994 - val_loss: 0.0517 - val_acc: 0.9905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CHDGYz_Mki4G",
        "colab_type": "code",
        "outputId": "ab918f8e-3d4b-49ec-dbb3-80da35b54a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "H.history.keys()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "G1s_nCBWk-91",
        "colab_type": "code",
        "outputId": "5010e90a-afc3-4b6a-b65e-ad93df43ccb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(H.history['acc'])\n",
        "plt.plot(H.history['val_acc'],'r')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f838f5b7a58>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VFXawPHf9JaQRhARFQseRWzo\nrqAiIlhXFhV7w9V11Rd27a4Fpcmirl1cu+7q6iIKqGsv2LFQ1FXUAwioFCE9mUyfe98/7iQkkDKk\nEDLzfD+fkMwtc8+TCc+cee6559pM00QIIURmsXd1A4QQQnQ8Se5CCJGBJLkLIUQGkuQuhBAZSJK7\nEEJkIGdXN6BOSUlNm4ftFBT4qagIdWRzugWJO7tka9yQvbGnE3dxca6tqeUZ0XN3Oh1d3YQuIXFn\nl2yNG7I39vbEnRHJXQghRGOS3IUQIgNJchdCiAwkyV0IITJQWqNllFIDgZeAu7XWMzZZNxL4G5AE\nXtNaT00tvxsYDJjAZVrrBR3ZcCGEEM1rNbkrpQLA/cC7zWxyH3AMsAb4QCk1GygG+muthyil9gKe\nAIZ0TJOFEEK0Jp2yTBQ4Hli76Qql1K5Audb6F621AbwGjEh9vQigtf4eKFBK9eiwVgshhGhRqz13\nrXUCSCilmlrdGyhp8HgDsBvQE1jUYHlJatvq5o5TUOBv15jO4uLcNu/bnUnc2WVbijtpmISjCRIJ\ng6RhkEyaJA2TRNLAMEwcDhs+jxOP24nP7cDhaN8pvuLiXEKROOvLQ6wvD7GhIkQiYWCz2bDZsL5j\nffd5HOTnesnP9VCQ6yEvx4OzleMnkwbBcNz6CsWoCcUJReKYJtbzY8NmT323gdNhx+Vs+OXA5bST\nSBpU18aoCcWoqY1RHYoRDMUJRxMYhnWtpmGa1M22nuNzce7xe+F1N52O2/qad/QVqk1eKdXC8nrt\nufqsuDiXkpKaNu/fXUnc2aVh3IZpUhWMUVIZpqw6QiSWJBZPfSUMojHru9tpJ8fnIuBzEfA5yfG5\nyPG5SBomFdVRKoJRKmo2foUicRwOO06HDYfd+u502LEB4ViSUCRBOBonFE0Qjia3qP1Ohw2Py4HP\n48TvdRLwugh4nQR8LvxeJ16Xg3jSenNIJAziqe/ReJKqUJx1pbUEw/E2//5yfC68bgemaWKYYBgm\nhmliGCYJwyQa27J4OorDbuPgPYvZviiw2bp0/tabS/7tTe5rsXrkdXZILYttsrwPsK6dxxJiqzFN\nk2g8STiaJBxNEI4liESTxBMGPs/GBOX3uPB6HNhtNkzTSkzhWJJILEkkmiASS1ITilFdG6OqNkZ1\nKE5VMEp1KEY8YdT3Ahv2PO12Gy6nHXeqJ2j9bMfrc7N6fTWllRFKqyIkkkaHxmwDvB6nleySBklj\n8xlBfB4nfo+Tnnk+/B4nPo8Tp9OOw27DYbdhb/A9mbR+h9FYkmg8Wf8GFIomWF8eJhoPpt02p8NO\nUZ6Xfr1zKc730TPfS888Hy6nHUzr9TJJfTchHE1QHYpRFbR6znW//0gsid1mw+kAu9OO3W7DbrPa\nXPeG40+94QS8Vqy21GtrPf/GYyQNk3giudkbktNuJ+CzniOnwZfXbf2d2KyPF6lPGdbvNOB1ddCr\n2OB31p6dtdarlFI9lFL9gNXACcDZWGWZycDDSqlBwFqtdfZ1tcRWEY4m+GVDkHVltfU91njqK5aw\nEnJdLzCRbPo/ZDxhWI+TZv1+6d6kzAZ43A7iiaYTYlPsNhsuVyoxWf9g7WqVNlo6do7PRd/iQKMk\n5/c4cbvsuF0OPE4Hbpf1phBPbCw11IbjBCMJasNx7DYb+bkeCnM99d97BNyNShemabUlmbR6uB6X\nA7u91Q/haUskDWojCUKROLWRBNFY0vqk4LTjctjryx5up51ddy6irCz9NwOR3miZA4E7gX5AXCl1\nCvAysFJrPRe4FPhPavPntNZLgaVKqUVKqfmAAYzrjMaLzGKaJtW1MVaX1LKmJEhtJIHX48DrduJ1\nO1JfTn4pC/PNsg38vL6Gn36tYUNFmLbMOldXctiYRBz4vVYpwu1y4PdYx/V7nHg9Vt3Y6bQTiVq9\nT6tEYSWnSCyJy2XfrK1et4Ncn4seAXejrxyfC7ut6URZl1StNxmDeDxJPGmQl+/Hlkji82yd+f5s\nNlvqd9Q5z+902MkLuMkLuFvdtiPfVLKFbVu5h2p7ZoWUGuy2KRJLsKEizIaKMKVVEZKG0eikF1gf\nS8uqIqwuCbK6ZMtrqn6Pk522y2Gn7XLpW5yD3+vE3eAEl7vBCa+GidzpsNW3obvY1l/vzpStsadZ\nc2/yD3mbmfJXdF/VoRi/bAiyekOQNSW1bKgIsb4iTFVtbIuepzjfS/++eexQnEPf4gA9/G4i8SSR\nWCJVw7Z+zgl4KAi42Hm7XIryvN0uSQuxNUhyF62KJ5JU1Vonp6zvUUqqIvUJfdMkbrNBUQ8ve/cr\noFeBn14FPorzrZNf5iYnvzAhL8dDn57+ZoeCbSpbe3FCbAlJ7lmitDKM/qWS4nwfu2yfi6uZQqpp\nmvxaHuKrZaV8tbyUtaW11EYSzT5vUQ8P++/ek769AvQtzqFvcU59IhdCdB1J7hnKNE3WlNSyeGkJ\ni5eW8POGjSMNnA4b/Xr3YPe+efTfIY9dd8hjfXmIL5eV8NWyUtZXhAGrB9670M9O2+WSn+MmL+Ah\nL8dNXo6bwlwvfYsD+DthCJcQov0kuWeQcDTBj2ur+G5lBYuXlrCh0krSDruNgbsWMrBfIaVVEZat\nqWLF2mqWr6nijU2ew+NycOAexezfvyf77FZED3/rIxlE5/PMfAam3IRjzqsk99yrU47hv3Uq3tnP\nU/HOh5h5+Z1yDLH1SHLvxipqIiz8YQNLV1ey7Jcqft5QUz8+2uNycNCevRi0R0/23bUnfm/jlzoS\nS1gJfnUVK9ZVU5jrYf/+xey1c36zJRvRNWylpeTcdD1UVeK//25qHnikw4/h+PYb/Pfcic0w8Lz8\nIpFzz+/wY4itS5J7N1JaFWbpL5Us/aUS/UsV68s3TtngdNjYfYc8+vfNZ48d81tN0l63kwH9ChnQ\nr3BrNF20Q+CWidirKsHjwTP3BWonTMLYvk/HHcA0yb3+amyGdcWrZ/YsSe4ZQJL7NqwyGOWbFWX8\n8FMlS3+poKw6Wr/O63YwaM9e9OuVwx475rd4klRsAdPE/cZr2GqqiZ52Zle3BueiBfiefZrEgIE4\n/zwO26WX4nv8EWonTOqwY3heeA7X558SPX4Utopy3PM/xr76F4y+O7a8YyKB96knSQw6kMT+gzqs\nPWlJJPD+8zES++xP4uDBrW9vmrjffgNbMEj05FM7rVnuN17D9dn8LdrHKCggfMl48Hg6tC2S3Lch\nScNgxdpqvllRxv9+LOPn9RtPgub4XBzQvydqx3zUTgX07RWg93Z5MiSwAzkXLSBn4o24vvgMgGBZ\nGeFLx3ddg5JJcq672mrLrXeQP/JwjJtuwvuvJ6i9/GrIyWn3IWw11QQm34Tp8xGcOh33+/Nwf/oJ\nnjkvEP7LFS3u63l+JrnXXQVAZMxp1N44sfU3hI5gmuRcfRm+Z58GIHrCaII3TcbYZdcmN3d+tZjA\nxBtxf/oJAJXFvYgPHdbhzbJt2ECPi8Zii0Zb33gTsWOO7/BzKZLcu1AsnuTn9UFWrK1i+dpqvl9V\nXj/s0GG3MaBfAfvuWsSAXQrp0zPQ7OXqon3sv/xMYNokvHNeACB63Ak4v1xEzsQbMHr3JnrSKV3S\nLu8zT+H6+ksiY04jPvgQ8PkIn/9HAnfcive5Z4hceHG7j+G/fTqODeupvW4Cxo47ER01mpzrr8Y7\n+7mWk7tp4n9oBqbDQWKvvfHOnoXn1ZcJXzyO0F+uwMztvNs3+G+bhu/Zp4nvs59VqnrlJdxvvkb4\ngj8RuupazPwCAOyrfyEwbTLe2bMAiA0bjuvD98m54Roq5n0Cro4d6eX752PYolFqr/orsaOPTXs/\nI7+g2Tem9pDpB7ai6lCMJSvKWb7WGq2yekOw0URThT087LtrEfvsVsReOxe0elFPl8VtmpBIdPh/\njnR1VNy2mmr8996F7+EHsEWjxPc/gNrJfyM+5FAcS74l//fHYouEqZo5p+09vbrJwLe0beVlFA4Z\nBLE4FZ8txtiuN8XFuZR+t4KiQQMwtu9D+aeLwdH2Upzjh+8pGH4Ixo47Uf7h5+D1AtDj/LPxvPZf\nyt+bT3LvgU3u63rvXfJPP4nIyadS849H8bzwHIFpk3GsW4vRs5jaa28gcs5YcG5B/zEeb/Zvqu41\n9/7rCXKvuZxkv12oeOVtzOJi3P99kZwpE3H8vAojP5/QVX/FVlaG/6EZ2CIR4vvuT+3kacQPHUrO\n1Zfje+oJgpOmEf6/P7fepmQyvd9xOEzRoAGQTFL25fcQ2Hz63rZoz/QDcqVJJyutDPPWFz9z6zOL\nueL+j3n0le94b/Ea1pQE2Wm7XEYc2JeLRg1g+sWD+fulh3DesXtyQP/itK/W3Npcn35C/jFHULTH\nzvjv/juE2j4Pf5dJJPA++RiFB++P/767MIp6Uv3AI1S+8R7xIYcCkNx7INX/ehZsNnqMPQvHt99s\n8WHs63+laGB/8o8fiXPB51u0b2D6LdgrKghdcz3GdhtnzzaLi4mcegaOVStxv/HaFrdp4xOZ5Fx/\nNbZkkuC02+oTO1glFgDvC881u7v/IetWyuFLxoHdTvS0Myn/dDG1103AFgqRe+0VFAw/BPe7b9Ha\n9JrOrxaTN/o4eu62A4Fpk7HVNH1PH/frr5Lz1ysxevakcuYczF69wGYj9vuTKP9kAcGJt4BhknPT\n9QTuuQOjoJDq+x+i8q33iR86FIDaG27CKCjA//fp2Nf/2mK7PHNfoEj1w9PC76GO94XnsJeVERl7\nYYcl9vaSnnsnqKiJ8tHXaxtdPGQDdtshjwP26MkeO+azU6/cdl/FuTXjdqxYTmDyzXhefwUAI7cH\n9ppqkn12oPaGm4mecjrYt05foc1xmybud94kMPkmnEs1RiCH8F+uIHTJePD5mtzF8+JsevzpDyS3\n603lq29j7LRz2ofz/20KgXvuqH8cGX2yNdJl534t7uf8+kvyjz6CZP89qHhvfn1vti5uh/6BwqG/\nJX7wECr/+2ba7WkqrujRx1L971mNV0YiFA3sjxkIUP7ld5u9ro7vv6Nw2GBiQw6l6qXXN3tu+/pf\n8d82De+zT2MzDGLDhhOcNG2zTwGblk2MHnnYq6usnv9fbyRy9nn1Pf/iZd9gjhgBdjuVc18lccCB\nTcZlKyvD/8C9GPn5hP94Cfj9m21T1/uPjDmNmgcfa/J5XB++T96ZY7DF4xiFhZR/uhizoJmRZYZB\nweEH41i5gvJF32L03r7p7dpAeu7biHjC4LXPfuKGRz7jxY9Xsqa0loG7FHLeMYq7xh/KDeceyHEH\n78xuffK6zeX5topyAhP+SsFhv8Xz+ivEfzuYitffpfzLJYT+ciX2slJ6jL+Y/GOG45r/cVc3t1mO\nb78h75TR5J19Go7lywif+wfKP/+K0BXXNJvYAaInjiE4dTqO9b+Sd8bJ2MrL0jtgbS2+fz2OUVhI\n5fMvER90IN6X5lB46EEEJk3AVlXZ9H6GQc51V2EzTYLT72iyTJFUexIdcRSuzz/FuXhheu1pKBgk\nMPFGTI+H4NRbN1/v9RIdNRrHurVNvqa+hx8AIHxp02UNY7veBO+6n4p5nxA74kjcH7xHwYjDyLli\nPPb1v2IL1uD/2xQKDzkQ7+xZxPfZj8o5r1D2P72x53/N5RQMPwTXvLdxLFsKo0ZBPE714081m9gB\nzKIiam+eQvgvVzaZ2AEi54wlvt8BeGfPwpU6ydqQ45v/0eP8s8FmIzLmNOzl5QSmT232mO55b+Nc\nqomedEqHJvb2kp57B/nfj2X8552lrK8Ik+NzceLQXRg8oPdmFw9tKc/cFzD9AWLHHLfZuqbidqxY\nju+RByHRxC3DXE4ip5xO4sDftH7gaBTfE4/iv+t27FWVJPvtQvCmKcRO+H2jGrJ1MnIy3jnPW7sd\ndwK1N08muVv/LQt0C2zJ623/dR3+6VPxznwGm2kSO3IkwYm3kNxrwBYdMzDxRvwP3k/8oN9SOffV\nVoeteZ94lNzrrqL2ymsJXTcBDAPPi7OtuvQvP2MUFhI9fhTYG9dz7WWleF59mcjok6l59J/Nxu36\n8H3yT/k9kRNPpuaRxtu1KBYj54Zr8T31xMa2NcH1yUfkn/Q7wmefR/DuGfXLbevXU3Tg3iT77kjF\n/EVpfVpzzXubnEkTcP7wPaY/gOn3YS8tJbl9H+tT36lnNHoe2/r1BG6fhveZp7AZBqbPhy0cpvq+\nB4mecXb6sbbAufALCo4fSWKvval496P6Twj2n38i//iR2Es2UP3oP4kddwIFww/BsWwplW9/QGLf\n/Td7rrwxv8f90fuUv/sxyX327ZD21WlPz12Sezutrwgx851lfP1jGXabjeGDduDEobt0yG2zbCUl\nFO27BzidlH/0BUa/XRqt3yxuwyD/dyNxLWq5Nxc5aQy1N05qusRgmrhfeZmcKTfh+GkVRl4+oauu\nJfyHi1pMaM7FC8m5+QZcX3yG6XQS/sMfCV31V8zCoi2KOR1pvd61tfgfuBf/P+7DFgqR2GtvgpNu\nIT58RNsOahjkXnoh3rmzqb3+JqvH38K2BUMG4VizmrLF31m14TqRCL5HHsR/753Ym6ktG7k9qPjw\nM4wd+jZa3ihu06Rg+KE49PeUf/E1xo47tdx+08T92isEptyEc+UKkv12ofz9T5vt3WIYFA7aG1tN\nDWVLltfX5P233kLgrtupue0uIn/4Y8vHbCiRwPvs0wRuvQVbKEToz5cTuvTPzR8fcHy3hJxJN+J+\nfx5Mm0bJRWmcAN0COZePw/fs09T87XYif7wEW3kZ+SccjXP5MoLTbiN80aXAxjfS+IG/ofLVtxu9\nETm++R+FIw4jNnQYVbP/26HtA0nuXZLcf/q1ho/+t5YPv15LImmy5075nDVyD/r2av/Y4zrexx8m\n93oriUSPPZ7qp2Y2Wr9p3J7//Jsel/0f0d/9ntobbt7s+eyrfyEwfQqur77E9HgI/+n/CF12JWaP\nPCCVoCfeiOvzT60EfcFFhK68Nv0EXffGMPVmHKtWWm8MV15L+IKW3xi2VIuvdzKJZ9Z/CPxtCo71\nv2IU96L2+puInHlOu0aWANiqqygcPAhbbZDyTxY2O6bb/fqr5I09k/BZ5xK854GmnytYg31d07cV\nNoqKmvydb/Z6z3yGHn+5lNAl46md8rdm291wnLfpcBA5/0Jqr74es6jl1zUw5Wb8M+6h6vGniY0a\nbY0IOWAvME3KFn/XthOH4TC2eKz+by4dtvIyeqp+Hf5/3FZaao1IMk0q5n1Mj0suxLXwC0LjLqN2\nYuMyTO4fx+J9ee5mnx5yx1+Md9Z/qHr2eWIjj+nQ9oEk962W3KtDMT5bsp5PvlnHL6kTpUU9PJx2\nZH8OUsXp3TQiGk070eUfdyTOLxeT2Gc/XF9/udkfUMO4bVWVFA4ZhC0UshLPJr2+eoaBZ/YsK/mt\nWY1RVETo8qtxfrl4Y2nl+FFWaWXX3dNqZ1Mx+p58FP+dqZLOzv0I3jyF2Amj2zQscFPFsWrK1m9e\ns3YsW0rO1Ik4l3yD6fMRunQ84fGXY+Y0fXf4tqhLqNETRlP9xNNNbpM3+jjcn35C+Yefd+iFKZv9\nncdiFB44EFttLZVvvofZYMQLgC0YxH//3fWjXqLHHk/tzVNJ7p5eycyx5FsKhx9C9LgTqP7Xs/Un\nImsvv5pQE52HztRZ/8frOlB1AwQiY06z5u7ZpNxkX7OawkMPwvT7rZOrefnYf11H4YEDrWGZH33R\nKQMKJLl3cnL//qcK5i1azVfLS0kaJg67jX13K+Kwfbdnn12LGt1UuCXexx8hZ/IEqh98nNjvRrW4\nrX3FjxQNPoDYEUcSnDSNghGHbTYeuWHcgRuuwf/YwwQnTLJOJrUmHMb/8AP47r0Le631RhXf7wBq\np/ytfjhge9nKy/DfdTu+Jx7FlkgQ/+1ggpOnpVfzb0oySe64i+ovNmpO5LQzqb3hZow+O7TtOC0x\nDPJHHYNrwedUznqR+BFHNlrt/GoxBUcfQWz4CKqem9uhh27q79x/zx0E/jalxf3i++xnjfM+7PAt\nPmbBsCE4flxG2f80+SccjeOnVZQvXtJoeObW0Gn/xxMJCo4ahnPJN8SGDafqmefB3fRMqL577yRn\n2mRCF11C7bTbCUybjP/eO6m5875Om4tHknsnvfCmafLmF78w673lAPQtzuGwfbdn8N7bbfFUuO6X\n59LjovOxmSaJAQOpeO+TFnux/r9PJ/D36VTf/xDR088iMOGv+B95sFG9t35o3JJvKRhxmNWD+OCz\nLSqB2DZswP/ogyTUntacG53Q+3CsWE5gykQ8r1k1yRZr/s0xTQI3Xov/sYdh332J7Ln35pt4fUTO\nHUtivwM6qulNcnzzPwqOOpzkrrtR8f6njZJB7iUX4J3zQpOJv72a+juvG3lir26ifm+zERs6rF3D\nVH333U3OLROJHvs7PG+8SuT0s6i5/6E2PVd7dGYHzvHjMjyznyd86fiWr6yNRikYNhjHqpVU/vdN\n8s4+FZxOyhYtaXHEVXt0enJXSt0NDAZM4DKt9YIG60YDE4AoMFNrPUMplQM8BRQAHmCy1rrFAbnb\nWnI3DJOZ85bxzsLVFOR6uHT0QHbboUeb7tfpmv8xeaediOn2kBywN64vPqPyhZeJH35E0zuYpnVC\nbt1aypYsx8zJbbLeW1ycS8mGavJ/fyyuzz+lcuYc4keObF/gncj16ScEbr4B19dN1/xbUpdkEnsN\nwDn/E0riXTtJWs5fr8T35GMEb55KePxlQOqj+0H7kNxjTyren98hJaiGuuLckn3NaooO2DiyqKWr\nVjvTtjAiDqyRP/lnjMHIycUerKH26usIXXtDpx2vU8e5K6WGAf211kOAC4H7GqyzAzOA44HDgVFK\nqb7A+YDWWg8HTgHuTSuSbUQ8keShl77lnYWr2aFngBvPPZDd++a1KbE7vv+OHuedCaZJ9ZP/Jpg6\n8eV7aEaz+zi/XIRzxY9Ej/tdfb3Y7JFH8OYp2MJhcm7e+MfkmT3LmtHvuBO26cQOEB9yKJVvvkf1\nA49g9CzGf//dFB68P94nHrWmM2iGZ9Z/yLllIsk+O1D1n9mQ3/U3kqi9bgJGURGBO27Fvm4tAL5H\nH8KWTBK6dHyHJ/auYuzQl1jq6s7Y4cO7JLFvS+JHHkX0uBOwB2usDsr5WzBiaCtL57PaCOBFAK31\n90CBUqrus0tPoFJrXaK1NoB3gZFAKVB3Kr4g9bhbCIbj3DnzKxbqEtSO+Vx3ziAKe3hb37EJ9jWr\nyTvjZOzVVdTc9yDxYcNJDDqI+MFD8LzzFo6lusn9PKkr9qKpy8DrRE87k/hvDsbzyku43p8H1dUE\nJk3A9HoJTp3epjZudXY70VPPoHz+ImtETyRK7nVXUXDEENxvv7HZpequee+Qe/k4jLx8qmbO6Zw6\nehuYBYXU3jgJW6iWwOQJ2II1eJ/+J0Zxry6baKyzhC+4CNPpJHTF1V3dlG1CcOp06wrYsRc0Hua6\njUknufcGSho8Lkktq/s5VynVXynlAoYD22mtZwI7KaWWAx8C3eKvoqwqwvR/L2Lp6ip+s2cvrjx9\n/zaPV7dVVpB3xsk41q0lOPGWRok6dIk1jWzdlX6NJBJ4587GKCoidsQmY7LtdmpuvRPTbifnhmtg\nwgQcG9YTuuyqLatfbwt8PkKXX035518RPvcPOJYvI+/s08g7ZXT9PC7Or78k74JzweGg6unnOu32\ncm0VOetc4gcMwjvnBXIuH4+9pprwhX/q8Hm5u1ps1ImUrlxXPz9LtjN22pmyb5ZRO2Xb7lC1WnNX\nSj0CvKq1fin1+GPgAq310tTjYcAtQBXwc+prNXC41vpPSqn9gMe11ge1dJxEImk6u/BmExsqQlxz\n30eUV0cYffhuXDBqb+z2Nn60jkTg6KPho4/gssvg7rsbf0xPJkEpWL0afv4ZGr77v/EGHHccjBsH\nM5op3YwbB//4h/XzrrvCkiWNJn7qlpYsgauvtuK32eDcc62fS0rghRfg5JO7uoVNW7AADj7Y+sTh\n81mvZ8+eXd0qkV2aTFTpXBu/lo09dYA+QP3VF1rrD4ChAEqp6cAqYBjwZmr910qpPkoph9a6iWvi\nLRUVbZ9dsL0nWxJJg9ueXUx5dYRTjtiN4wfvTFlZsPUdN2WauN99y5qYSv9gXUJ+/WQo3fy5vH+8\nhNzrr6H2jnsIXXN9/fLcx57EC1T87iQSzcRku+xaCp+zZqGrmjKdWE0cauJb3t5tSa+d4KlZuOa9\nQ87kCTifegqAmul3EBl6FDT4XWwrJ9cA6LcnOeeMxff0PwmfdhZB09OorR1pm4p7K8vW2NM8odrk\n8nSS+1vAZOBhpdQgYK3Wuv5oSqnXgbFALTAKuBPYATgYmK2U2hkItpTYu9rsD37kxzXVDB6wHccd\n3Mpl3M1wfPsNOZMm4P7wPUy7nfB5F1hTqTYzBC1yxjkEbpuG78lHCf35CqvnHQzief0Vkv12aXEs\nuFlQSPWTz5C/dhWxozefc6Y7ix85korDj9h43uH0s7q4Ra2rnTgVo88OhMde2NVNEaJeqzV3rfV8\nYJFSaj7WSJlxSqnzlVInpTZ5FOsN4GNguta6FHgY6KeU+gB4FrikU1rfAb5cVsKbX/xC70I/5x2r\ntnhEjP3XdeRcPo6CEYfh/vA9YsNHUPHefIJ33NNy7TUQIHLeBdhLS+uvIPS88Sq2UMiaT7uVdsQH\nHwIXt/9OPNskp5Po6Wd1i8QO1kim0FV/xZRyjNiGZPVFTKWVYSY9uYB40uCm8w7a4nlhvE8+Rs5k\na4rSxJ57WRNTHXlU2vvXX768y65UfPQFeWeOwT3vHco/XZTWrIryUTW7ZGvckL2xy3zubZBIGjz4\n0hJC0QRnH7XlE355nnuW3L9eienzUXPHvVTM+2SLEjuA0Xt7oieOwblU43nuWVwfvEf8gEGdOl2u\nECI7ZG1yn/Xeclauq2bI3r3wZvtKAAAXDklEQVQZuu+WTbDvmvc2uVeMx8jPp/LF14mc94ctu1dk\nA3XDInOvvQJbMrnZ2HYhhGiLrEzui/QG3lm4mu2L/Jx3zJbV2Z1fLSbvAuv2X1VPPUdS7dmutiT3\n2ZfY0GHYIhFrOtYTM+sCGCFE18i65F5aGeaJ137A7bTzfycOxONOf2y9feUK8s46FSJhqh98nMTg\nIR3SpvAl4wCIH37ENn3FmxCi+2jfPeC6oXlfriEcTXDesYoditOvs9tKSsg//STspSXU3HZXq1P2\nbonYyGOovvcfxA/umDcLIYTIquRumiYLf9iAx+3g0IFbMB91MEjeOafiWLWS2iuu3rLbi6XDZiN6\n5jkd+5xCiKyWVWWZn9cHKa2KsP/uPXGlO9WBadLjkgtwfbmY8JnnELrups5tpBBCdICsSu4L9QYA\nDlLFae/jmT0Lz1tvEDt8OME77s2YqVyFEJkta5K7aZos+GEDbpedgbumd8NnW83GKXVr7roPXG2b\nIVIIIba2rEnuq0tq2VARZr9dCvDr7zabN7wp/jtus6bU/cuV3W9KXSFEVsua5L7wB6skc+KPH1J4\n5KEEJt7Y4vYO/QO+Rx8kuXM/QuMv3xpNFEKIDpM9yV1vwOW003/BPAD8D83A92Az86WbJjk3XIMt\nkSB4y23df650IUTWyYrkvqa0lnVlIQZt78U7/yOS/XYh2Xt7cibegGfuC5tt73l5Lu6PPiB61DHE\njsmsKXWFENkhK5L7olRJ5ujgMmyxGJGTxlD1n9kYuT3IHX8xro8+2LhxMEhg4o2YbjfBqbd2UYuF\nEKJ9siK5L9QbcDps7LXkUwBiRx1Lcu+BVP/rWbDZ6DH2rPr7dgbuuQPH2jWExl+GsetuXdlsIYRo\ns4xP7r+Wh1hdUsvAnfIJvPsWRs+eJAZZt3ONH3Y4NTMexh6sIe/MMbjeexffg/eT7Lsjob9c1cUt\nF0KItsv45L4odeHSCPsG7CUbiI08ptGt76InjiE4dTqO9b+Sf/pJ2OJxglOmg9/fVU0WQoh2y/jk\nvvCHEhx2G/sv/QKA6FHHbrZN+OJxhC79MwCxI47s0EnBhBCiK2T0xGEbKsP8tL6GgbsWEnj4LUyX\ni/jwI5vctnbiVOJDDyf+28EyxYAQotvL6OReV5I5rMjE9c3XxIYNx8zJbXpju90q2QghRAbI6LLM\nwh9KsNts/HblQgBiR29ekhFCiEyUVs9dKXU3MBgwgcu01gsarBsNTACiwEyt9YzU8rOBa4EEcLPW\n+tUObnuLSqvCrFxXzYB+BfR45W2g6Xq7EEJkolZ77kqpYUB/rfUQ4ELgvgbr7MAM4HjgcGCUUqqv\nUqoImAgcBpwAjO6EtrdosS4B4OCdc3F/+D4JtSdGv122djOEEKJLpNNzHwG8CKC1/l4pVaCU6qG1\nrgZ6ApVaW5lUKfUuMBIIA+9orWuAGuBPndL6Fvy0vgaAA39dgi0SISa9diFEFkknufcGFjV4XJJa\nVp36OVcp1R9YBQwH3k9t51dKvQwUAJO01u+2dJCCAj/OdO+O1ITi4sYnSs3UiJftv/jQasxpJ+Mv\nbuZkaje2adzZQuLOPtkae1vjbstomfpxglprUyk1FngCqAJWNlhfBJwE7Ay8p5TaWWvd7CTqFRWh\nNjTFUlycS0lJTaNlNcEomCaO117FKCigbPeBsMk23V1TcWcDiTv7ZGvs6cTdXPJPJ7mvxeqp1+kD\nrKt7oLX+ABgKoJSajtWD9wHztdYJ4EelVA1QDGxI43gdIhJPslvpKhzr1hIZcxo4M3rUpxBCNJLO\nUMi3gFMAlFKDgLWpWjqpZa8rpXoppQLAKOCd1D5HKqXsqZOrOUBph7e+BdGYweCfrGqSDIEUQmSb\nVruzWuv5SqlFSqn5gAGMU0qdD1RprecCj2IlcxOYrrUuBVBKvQB8lnqaP2utjc4IoDmxeJKDln+B\n6XAQO3Lk1jy0EEJ0ubRqFVrr6zZZ9HWDdXOAOU3s8zDwcLta1w6eilJ2X7uU2KFDMfPyu6oZQgjR\nJTL2CtW9tTVRmAyBFEJko4xM7qZp8psfPgEgdowkdyFE9snI5J7cUMKgVV+ypm9/krv17+rmCCHE\nVpeRyd354hycRpJvD5ZZHoUQ2Skjk3tg7vMY2NBDJLkLIbJTxiV3+6qV+Bcv4H877UN8u96t7yCE\nEBko45K7d87zALy/1zC8rrbPVSOEEN1ZZiV308TzwnMkPR7m7z4EtyuzwhNCiHRlVPZzfv0lzuXL\nKDl0JGGPH49beu5CiOyUUcndM3sWAD+PHAUgZRkhRNbKnOSeSOCd8wJGQQGr9z8EALckdyFElsqY\n5O766APsJRuIjj6ZiGkldY8kdyFElsqY5O594TkAImNOJxpPWsuk5i6EyFKZkdxra3G/9grJnXYm\n8duD65O7lGWEENkqM5L7yy9jrw0SGXMq2GxEY1Zyl7KMECJbZUZyf+YZAKJjTre+p3ruMhRSCJGt\nun1yt5WWwhtvEN93f5J7KKBBcpeeuxAiS3X75O55aQ4kk0RPOa1+mZRlhBDZrvsn99dfBbud6Emn\n1C/bWJbp9uEJIUSbpHUP1W1Z5NTTcZ96MkaDGSCjcQOnw47DLsldCJGd0kruSqm7gcGACVymtV7Q\nYN1oYAIQBWZqrWc0WOcDvgWmaq3/2YHtrhc9/SwozoWSmo3L4kk8MmmYECKLtZoBlVLDgP5a6yHA\nhcB9DdbZgRnA8cDhwCilVN8Gu08Ayju0xWmIxpIyUkYIkdXS6d6OAF4E0Fp/DxQopXqk1vUEKrXW\nJVprA3gXGAmglNoTGAC82uGtboXVc5fkLoTIXumUZXoDixo8Lkktq079nKuU6g+sAoYD76e2uxMY\nD4xNpyEFBX6czrYn5OLi3PqfY/EkAX+g0bJMlQ0xNkXizj7ZGntb427LCVVb3Q9aa1MpNRZ4AqgC\nVgI2pdR5wKda65VKqbSetKIi1IamWIqLcylJ1dwNwySWMHBA/bJM1TDubCJxZ59sjT2duJtL/ukk\n97VYPfU6fYB1dQ+01h8AQwGUUtOxevAnAbsqpU4A+gJRpdRqrfU7aRyvXeTqVCGESC+5vwVMBh5W\nSg0C1mqt699KlFKvY5VeaoFRwJ1a65kN1k8CVm2NxA5ydaoQQkAayV1rPV8ptUgpNR8wgHFKqfOB\nKq31XOBRrDcAE5iutS7tzAa3RpK7EEKkWXPXWl+3yaKvG6ybA8xpYd9JbWpZG8nUA0IIkQHTD2wq\nFjcAqbkLIbJbxiX3SDwBIFeoCiGyWsZlwGgs1XOXsowQIotlXHKPyVBIIYTIvOQekdEyQgiRecld\nRssIIUQGJve6soxbyjJCiCyWccm9rizjlZ67ECKLZVxylytUhRAiA5N7LCZlGSGEyLjkHpWyjBBC\nZF5yl6GQQgiRgcm9rizjkukHhBBZLOMyYDRu4HE5sNtsrW8shBAZKuOSeySelEnDhBBZL+OyYCye\nxC31diFElsu45B6NJWXSMCFE1su85B5PyjBIIUTWy6jknkgaJA1TyjJCiKyXUcldph4QQghLWjfI\nVkrdDQwGTOAyrfWCButGAxOAKDBTaz0jtfx2YGjqGNNTN9LuVHXT/Xql5i6EyHKt9tyVUsOA/lrr\nIcCFwH0N1tmBGcDxwOHAKKVUX6XUcGBgap9jgXs6o/Gbquu5S1lGCJHt0inLjABeBNBafw8UKKV6\npNb1BCq11iVaawN4FxgJfAicmtqmEggopTo940pZRgghLOmUZXoDixo8Lkktq079nKuU6g+sAoYD\n72utk0BtavsLgddSy5pVUODH6Wx7Ui4uzmV9dRSAwnwfxcW5bX6u7iRb4tyUxJ19sjX2tsadVs19\nE/XX9WutTaXUWOAJoApY2XB9qh5/IXB0a09aURFqQ1MsxcW5lJTUsL6kBoBEPEFJ6udMVhd3tpG4\ns0+2xp5O3M0l/3SS+1qsnnqdPsC6ugda6w+wTpyilJqO1YNHKXUMcCNwrNa6Ko3jtFs0bgBSlhFC\niHRq7m8BpwAopQYBa7XW9W8lSqnXlVK9lFIBYBTwjlIqD/g7cILWurwT2t0kuTm2EEJYWu25a63n\nK6UWKaXmAwYwTil1PlCltZ4LPIr1BmBiDXksVUr9Cetk6yylVN1Tnae1/rkzgqhTf0JVhkIKIbJc\nWjV3rfV1myz6usG6OcCcTbZ/BHik3a3bQjJaRgghLJl1haqUZYQQAsi05C5lGSGEADI1uUvPXQiR\n5SS5CyFEBsqs5B6TsowQQkCmJXfpuQshBJCByd1us+F02FrfWAghMlhmJfeYgcftwGaT5C6EyG6Z\nldzjCTyujApJCCHaJKMyYTRuSL1dCCHIuOSelOQuhBBkUHI3TZNYLCnDIIUQggxK7rGEgYkMgxRC\nCMig5C5j3IUQYqOMSe4xuTpVCCHqZUxyj0jPXQgh6mVMcpeyjBBCbJQxyV3KMkIIsVHGJHcpywgh\nxEYZk9w3lmUyJiQhhGiztG6QrZS6GxgMmMBlWusFDdaNBiYAUWCm1npGa/t0hljcAMAtPXchhGi9\n566UGgb011oPAS4E7muwzg7MAI4HDgdGKaX6trRPZ6m7UYdXau5CCJFWWWYE8CKA1vp7oEAp1SO1\nridQqbUu0VobwLvAyFb26RRScxdCiI3SKcv0BhY1eFySWlad+jlXKdUfWAUMB95vZZ8mFRT4cTrb\nnpidqaTeqziX4uLcNj9Pd5NNsTYkcWefbI29rXGnVXPfRP2dMLTWplJqLPAEUAWsbLi+qX2aU1ER\nakNTLMXFuVRUhgGIhKKUlNS0+bm6k+Li3KyJtSGJO/tka+zpxN1c8k8nua/F6nXX6QOsq3ugtf4A\nGAqglJqO1YP3trRPZ5CyjBBCbJROzf0t4BQApdQgYK3Wuv6tRCn1ulKql1IqAIwC3mltn84QSyV3\nGS0jhBBp9Ny11vOVUouUUvMBAxinlDofqNJazwUexUrmJjBda10KlG66T6dFkCKjZYQQYqO0au5a\n6+s2WfR1g3VzgDlp7NOpZG4ZIYTYKGMu54zGkzgdduz2Vs/dCiFExsug5G7I1ANCCJGSMdkwGktK\nvV0IIVIyJ7nHkzJSRgghUjIqucvJVCGEsGREck8aJvGEIWUZIYRIyYjkHo0lALmASQgh6mREco/E\nZIy7EEI0lCHJ3eq5y/1ThRDCkhnJPSo9dyGEaCgzkntdz12SuxBCABmT3OXm2EII0VBGZMNofc29\nLfceEUKIzJMRyT0clZ67EEI0lBHZMCo1dyGEaCQjknt9zV2GQgohBJApyT0qPXchhGgoM5K7XKEq\nhBCNZEhylytUhRCioQxJ7tJzF0KIhtIaGK6UuhsYDJjAZVrrBQ3WjQPOAZLAQq315UqpPsATgAdw\nAFdorRd1dOPryBWqQgjRWKs9d6XUMKC/1noIcCFwX4N1PYBrgKFa68OAAUqpwcCVwFyt9XDgOmBa\nZzS+jvTchRCisXTKMiOAFwG01t8DBamkDhBLfeUopZyAHygHSoGi1DYFqcedJhpLYgNcchGTEEIA\n6SX33kBJg8clqWVorSPAZGAF8BPwudZ6KXA3cLpS6gfgUeDmjmz0psLRBG6XA7vN1pmHEUKIbqMt\nk7HUZ9BUD/4GYA+gGpinlNoPGAXM0lpPU0qdANwBnNzSkxYU+HE621ZWicYS+DxOiotz27R/d5aN\nMYPEnY2yNfa2xp1Ocl9Lqqee0gdYl/p5L2CF1roUQCn1EXAgcCgwIbXN28A/WjtIRUUozSZvLhJL\n4nLaKCmpafNzdEfFxblZFzNI3NkoW2NPJ+7mkn86ZZm3gFMAlFKDgLVa67qjrQL2Ukr5Uo8PApYB\ny4GDU8t+k1rWaSLRhJxMFUKIBlrtuWut5yulFiml5gMGME4pdT5QpbWeq5T6O/CeUioBzNdaf6SU\nWg48rpQ6LfU0f+msAMDquUtyF0KIjdKquWutr9tk0dcN1j0MPLzJ9uuA49vdujQkkgZJw5SrU4UQ\nooFuP3YwGpcx7kIIsanun9zlAiYhhNhM90/ucZnLXQghNpU5yV167kIIUa/7J/dUWcYtyV0IIep1\n/+Qel5tjCyHEprp9RozGDQC87rbMpCCEEJmp2yf3urnc3dJzF0KIet0+I8ZSPXc5oSqEEBt1++Re\nV3P3ylBIIYSo1/2Tu1zEJIQQm+n+yT0uQyGFEGJTGZPcpSwjhBAbZUxyl7KMEEJs1P2Tu1yhKoQQ\nm+n+yV167kIIsZmMSO4Ouw2nw9b6xkIIkSW6f3KPGXjdDmw2Se5CCFGn20/Icti+24O9279HCSFE\nh+r2yf3o3+xIcXEuJSU1Xd0UIYTYZkiXVwghMlBaPXel1N3AYMAELtNaL2iwbhxwDpAEFmqtL08t\nvzq1PA78X8N9hBBCdK5We+5KqWFAf631EOBC4L4G63oA1wBDtdaHAQOUUoOVUnsDZwAHARcDJ3RG\n44UQQjQtnZ77COBFAK3190qpAqVUD611NRBLfeUopYKAHygHTgJmaa0TwOLUlxBCiK0kneTeG1jU\n4HFJalm11jqilJoMrADCwEyt9VKlVD8gqZR6A3ABV2qtv27pIAUFfpzOtl+IVFyc2+Z9uzOJO7tk\na9yQvbG3Ne62jJapH1CeKsvcAOwBVAPzlFL7pbZxAMcBhwKPAb9p6UkrKkJtaIolW0fLSNzZJVvj\nhuyNPZ24m0v+6ST3tVg99Tp9gHWpn/cCVmitSwGUUh8BBwLrgR+01ibwcaonL4QQYitJZyjkW8Ap\nAEqpQcBarXXdW8kqYC+llC/1+CBgGfA6cExqnz2BXzqwzUIIIVphM02z1Y2UUrcChwMGMA44AKjS\nWs9VSl0M/AFIAPO11tem9pkMHJ16iiu11p92QvuFEEI0Ia3kLoQQonuRK1SFECIDSXIXQogMJMld\nCCEykCR3IYTIQJLchRAiA0lyF0KIDNTtb9bR0nTEmUYpNRB4Cbhbaz1DKbUj8DTWVA/rgHO11tGu\nbGNnUErdDgzF+nudDiwgw+NWSvmBfwLbAV5gKvA1GR53ndSFkd9ixf0uGR63UuoI4HlgSWrRN8Dt\ntCPubt1zb2k64kyjlAoA92P9odeZAjygtR4KLAcu6Iq2dSal1HBgYOo1Pha4hyyIGxiFdX+EYcBp\nwF1kR9x1JmDNMAvZE/cHWusjUl9/pp1xd+vkzibTEQMFqcnMMlEUOB5rrp86RwAvp37+LzByK7dp\na/gQODX1cyUQIAvi1lo/p7W+PfVwR2A1WRA31E9ZMgB4NbXoCLIg7iYcQTvi7u5lmWanI+6a5nSe\n1Nz4CaVUw8WBBh/TNgDbb/WGdTKtdRKoTT28EHgNOCbT466jlJoP9MW64c07WRL3ncB4YGzqccb/\nnacMUEq9DBQCk2ln3N29574pW+ubZKyMjl0pNRoruY/fZFVGx621PgT4PfBvGseakXErpc4DPtVa\nr2xmk4yMG2vCxcnAaKw3tcdp3Pne4ri7e3JvaTribBBsMCPnDjQu2WQMpdQxwI3AcVrrKrIgbqXU\ngakT5mitv8L6j16T6XEDvwNGK6U+A/4I3EQWvN5a6zWpUpyptf4R+BWrzNzmuLt7cm9pOuJs8A4w\nJvXzGOCNLmxLp1BK5QF/B07QWtedYMv4uLFmYb0KQCm1HZBDFsSttT5da/0brfVgrJv8TCUL4lZK\nna2Uujr1c2+sUVJP0o64u/2skJtOR9za7fy6K6XUgVi1yH5AHFgDnI01XM4L/AT8QWsd76Imdgql\n1J+AScDSBovHYv3Hz+S4fVgfzXcEfFgf2RcCT5HBcTeklJqEdc+IN8nwuJVSucCzQD7gxnq9v6Qd\ncXf75C6EEGJz3b0sI4QQogmS3IUQIgNJchdCiAwkyV0IITKQJHchhMhAktyFECIDSXIXQogM9P9r\njP4+2fdgrQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "-AGE67k2lGxL",
        "colab_type": "code",
        "outputId": "2fdf53da-5446-4f12-e846-0d3f14dd4331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(H.history['loss'])\n",
        "plt.plot(H.history['val_loss'],'r')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f838f556f60>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD5CAYAAAA6JL6mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4RIGVSojmy-R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ]
    },
    {
      "metadata": {
        "id": "tnigE74rm39a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unlabeled_images_test = pd.read_csv('gdrive/My Drive/dataML/test.csv')\n",
        "#unlabeled_images_test = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Fotf1KrpXVE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_unlabeled = unlabeled_images_test.values.reshape(unlabeled_images_test.shape[0],28,28,1)/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jeRnCHzdutQ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_unlabeled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3M_fePteu-3X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_label = np.argmax(y_pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RX5PuSUmvRri",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save csv"
      ]
    },
    {
      "metadata": {
        "id": "zU5Q1fSRvVbn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imageId = np.arange(1,y_label.shape[0]+1).tolist()\n",
        "prediction_pd = pd.DataFrame({'ImageId':imageId, 'Label':y_label})\n",
        "prediction_pd.to_csv('gdrive/My Drive/dataML/out_cnn3.csv',sep = ',', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_qetEX7AgBQY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "4keUL7d0gBQZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Helper functions for batch learning"
      ]
    },
    {
      "metadata": {
        "id": "czdbjPfcgBQd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot_encode(vec, vals=10):\n",
        "    '''\n",
        "    For use to one-hot encode the 10- possible labels\n",
        "    '''\n",
        "    n = len(vec)\n",
        "    out = np.zeros((n, vals))\n",
        "    out[range(n), vec] = 1\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Afc2XmK2gBQh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CifarHelper():\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.i = 0\n",
        "        \n",
        "        # Intialize some empty variables for later on\n",
        "        self.training_images = None\n",
        "        self.training_labels = None\n",
        "        \n",
        "        self.test_images = None\n",
        "        self.test_labels = None\n",
        "    \n",
        "    def set_up_images(self):\n",
        "        \n",
        "        print(\"Setting Up Training Images and Labels\")\n",
        "        \n",
        "        # Vertically stacks the training images\n",
        "        self.training_images = train_images.as_matrix()\n",
        "        train_len = self.training_images.shape[0]\n",
        "        \n",
        "        # Reshapes and normalizes training images\n",
        "        self.training_images = self.training_images.reshape(train_len,28,28,1)/255\n",
        "        # One hot Encodes the training labels (e.g. [0,0,0,1,0,0,0,0,0,0])\n",
        "        self.training_labels = one_hot_encode(train_labels.as_matrix().reshape(-1), 10)\n",
        "        \n",
        "        print(\"Setting Up Test Images and Labels\")\n",
        "        \n",
        "        # Vertically stacks the test images\n",
        "        self.test_images = test_images.as_matrix()\n",
        "        test_len = self.test_images.shape[0]\n",
        "        \n",
        "        # Reshapes and normalizes test images\n",
        "        self.test_images = self.test_images.reshape(test_len,28,28,1)/255\n",
        "        # One hot Encodes the test labels (e.g. [0,0,0,1,0,0,0,0,0,0])\n",
        "        self.test_labels = one_hot_encode(test_labels.as_matrix().reshape(-1), 10)\n",
        "\n",
        "        \n",
        "    def next_batch(self, batch_size):\n",
        "        # Note that the 100 dimension in the reshape call is set by an assumed batch size of 100\n",
        "        x = self.training_images[self.i:self.i+batch_size]\n",
        "        y = self.training_labels[self.i:self.i+batch_size]\n",
        "        self.i = (self.i + batch_size) % len(self.training_images)\n",
        "        return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1qAiPT1-gBQp",
        "colab_type": "code",
        "outputId": "d95d0cd8-dc1f-42bd-8398-258b24416ea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Before Your tf.Session run these two lines\n",
        "ch = CifarHelper()\n",
        "ch.set_up_images()\n",
        "\n",
        "# During your session to grab the next batch use this line\n",
        "# (Just like we did for mnist.train.next_batch)\n",
        "# batch = ch.next_batch(100)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting Up Training Images and Labels\n",
            "Setting Up Test Images and Labels\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QUkUv8sKgBQw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating the Model\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "l1XSMzIpgBQx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Create 2 placeholders, x and y_true. Their shapes should be: **\n",
        "\n",
        "* x shape = [None,28,28,1]\n",
        "* y_true shape = [None,10]\n",
        "\n",
        "** Create one more placeholder called hold_rate. No need for shape here. This placeholder will just hold a single probability for the dropout. **"
      ]
    },
    {
      "metadata": {
        "id": "8Y_4DDQvgBQz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None,28,28,1])\n",
        "y_true = tf.placeholder(tf.float32, shape=[None,10])\n",
        "hold_rate = tf.placeholder(tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7oP9cPk4gBQ2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Helper Functions\n",
        "\n",
        "** Grab the helper functions from MNIST with CNN (or recreate them here yourself for a hard challenge!). You'll need: **\n",
        "\n",
        "* init_weights\n",
        "* init_bias\n",
        "* conv2d\n",
        "* max_pool_2by2\n",
        "* convolutional_layer\n",
        "* normal_full_layer"
      ]
    },
    {
      "metadata": {
        "id": "NZNfr2JjgBQ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def init_weights(shape):\n",
        "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
        "    return tf.Variable(init_random_dist)\n",
        "\n",
        "def init_bias(shape):\n",
        "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
        "    return tf.Variable(init_bias_vals)\n",
        "\n",
        "def conv2d(x, W):\n",
        "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "# x -->[batch, in_height, in_width, in_channels]\n",
        "# W --> [filter_height, filter_width, in_channels, out_channels]\n",
        "\n",
        "def max_pool_2by2(x):\n",
        "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
        "                          strides=[1, 2, 2, 1], padding='SAME')\n",
        "def convolutional_layer(input_x, shape):\n",
        "    W = init_weights(shape)\n",
        "    b = init_bias([shape[3]])\n",
        "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
        "\n",
        "def normal_full_layer(input_layer, size):\n",
        "    input_size = int(input_layer.get_shape()[1])\n",
        "    W = init_weights([input_size, size])\n",
        "    b = init_bias([size])\n",
        "    return tf.matmul(input_layer, W) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8IvozQVkgBQ5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create the Layers\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "iC0xMN4pgBQ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "convo_1 = convolutional_layer(x,shape=[6,6,1,32])\n",
        "convo_1_pooling = max_pool_2by2(convo_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LA4Ho_sGgBQ8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "convo_2 = convolutional_layer(convo_1_pooling,shape=[6,6,32,64])\n",
        "convo_2_pooling = max_pool_2by2(convo_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1jkM0KsegBQ_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "convo_2_flat = tf.reshape(convo_2_pooling,[-1,7*7*64])\n",
        "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b_nkIdaogBRB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "full_one_dropout = tf.nn.dropout(full_layer_one,rate=hold_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uhl1VK5_gBRE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = normal_full_layer(full_one_dropout,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tT4TvNz-gBRI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loss Function"
      ]
    },
    {
      "metadata": {
        "id": "wkqQ5GurgBRJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true,logits=y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jmnEUVWxgBRM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "MoyIlzCagBRN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.00002)\n",
        "train = optimizer.minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "47rAzeVNgBRP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Intialize Variables"
      ]
    },
    {
      "metadata": {
        "id": "7WG1AszIgBRQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E17jzK2ngBRT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Predict"
      ]
    },
    {
      "metadata": {
        "id": "it2XCW8MgBRT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unlabeled_images_test = pd.read_csv('gdrive/My Drive/dataML/test.csv')\n",
        "#unlabeled_images_test = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qi7x2bto3reY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_unlabeled = unlabeled_images_test.values.reshape(unlabeled_images_test.shape[0],28,28,1)/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6N2kCQS2gBRW",
        "colab_type": "code",
        "outputId": "a862a92c-2465-4c70-d21b-ecf883a217a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(X_unlabeled[1].reshape(28,28))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3521e677b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njc4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "twsVFTqWgBRY",
        "colab_type": "code",
        "outputId": "7057481b-f98f-4aed-de57-205006702b59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_unlabeled.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "rseSYLjggBRb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Saving the Model"
      ]
    },
    {
      "metadata": {
        "id": "OwdUgOG4gBRc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xGdHTpE0gBRe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Graph Session\n",
        "\n",
        "** Perform the training and test print outs in a Tf session and run your model! **"
      ]
    },
    {
      "metadata": {
        "id": "pQHEYbyZgBRf",
        "colab_type": "code",
        "outputId": "dfb3ba20-2e2f-4392-f2e8-39166d1e2601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 42517
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for i in range(50000):\n",
        "        batch = ch.next_batch(100)\n",
        "        sess.run(train, feed_dict={x: batch[0], y_true: batch[1], hold_rate: 0.5})\n",
        "        \n",
        "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
        "        if i%100 == 0:\n",
        "            \n",
        "            print('Currently on step {}'.format(i))\n",
        "            print('Accuracy is:')\n",
        "            # Test the Train Model\n",
        "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
        "\n",
        "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
        "\n",
        "            print(sess.run(acc,feed_dict={x:ch.test_images,y_true:ch.test_labels,hold_rate:1.0}))\n",
        "            print('\\n')\n",
        "        \n",
        "    saver.save(sess,'models_saving/my_model.ckpt')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Currently on step 0\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 1000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 1100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 1200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 1300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 1400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 1500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 1600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 1700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 1800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 1900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 2000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 2100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 2200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 2300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 2400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 2500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 2600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 2700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 2800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 2900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 3000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 3100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 3200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 3300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 3400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 3500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 3600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 3700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 3800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 3900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 4000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 4100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 4200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 4300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 4400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 4500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 4600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 4700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 4800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 4900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 5000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 5100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 5200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 5300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 5400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 5500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 5600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 5700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 5800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 5900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 6000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 6100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 6200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 6300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 6400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 6500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 6600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 6700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 6800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 6900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 7000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 7100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 7200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 7300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 7400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 7500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 7600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 7700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 7800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 7900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 8000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 8100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 8200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 8300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 8400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 8500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 8600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 8700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 8800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 8900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 9000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 9100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 9200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 9300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 9400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 9500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 9600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 9700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 9800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 9900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 10000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 10100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 10200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 10300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 10400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 10500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 10600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 10700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 10800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 10900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 11000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 11100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 11200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 11300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 11400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 11500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 11600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 11700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 11800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 11900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 12000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 12100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 12200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 12300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 12400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 12500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 12600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 12700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 12800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 12900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 13000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 13100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 13200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 13300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 13400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 13500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 13600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 13700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 13800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 13900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 14000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 14100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 14200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 14300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 14400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 14500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 14600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 14700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 14800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 14900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 15000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 15100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 15200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 15300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 15400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 15500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 15600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 15700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 15800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 15900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 16000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 16100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 16200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 16300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 16400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 16500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 16600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 16700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 16800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 16900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 17000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 17100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 17200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 17300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 17400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 17500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 17600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 17700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 17800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 17900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 18000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 18100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 18200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 18300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 18400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 18500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 18600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 18700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 18800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 18900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 19000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 19100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 19200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 19300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 19400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 19500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 19600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 19700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 19800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 19900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 20000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 20100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 20200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 20300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 20400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 20500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 20600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 20700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 20800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 20900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 21000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 21100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 21200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 21300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 21400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 21500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 21600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 21700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 21800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 21900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 22000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 22100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 22200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 22300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 22400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 22500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 22600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 22700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 22800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 22900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 23000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 23100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 23200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 23300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 23400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 23500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 23600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 23700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 23800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 23900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 24000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 24100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 24200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 24300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 24400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 24500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 24600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 24700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 24800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 24900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 25000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 25100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 25200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 25300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 25400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 25500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 25600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 25700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 25800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 25900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 26000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 26100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 26200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 26300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 26400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 26500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 26600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 26700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 26800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 26900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 27000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 27100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 27200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 27300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 27400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 27500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 27600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 27700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 27800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 27900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 28000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 28100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 28200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 28300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 28400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 28500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 28600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 28700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 28800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 28900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 29000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 29100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 29200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 29300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 29400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 29500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 29600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 29700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 29800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 29900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 30000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 30100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 30200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 30300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 30400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 30500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 30600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 30700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 30800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 30900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 31000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 31100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 31200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 31300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 31400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 31500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 31600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 31700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 31800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 31900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 32000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 32100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 32200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 32300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 32400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 32500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 32600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 32700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 32800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 32900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 33000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 33100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 33200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 33300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 33400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 33500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 33600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 33700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 33800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 33900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 34000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 34100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 34200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 34300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 34400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 34500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 34600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 34700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 34800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 34900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 35000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 35100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 35200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 35300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 35400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 35500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 35600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 35700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 35800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 35900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 36000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 36100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 36200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 36300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 36400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 36500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 36600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 36700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 36800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 36900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 37000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 37100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 37200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 37300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 37400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 37500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 37600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 37700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 37800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 37900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 38000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 38100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 38200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 38300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 38400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 38500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 38600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 38700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 38800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 38900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 39000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 39100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 39200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 39300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 39400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 39500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 39600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 39700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 39800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 39900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 40000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 40100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 40200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 40300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 40400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 40500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 40600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 40700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 40800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 40900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 41000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 41100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 41200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 41300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 41400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 41500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 41600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 41700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 41800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 41900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 42000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 42100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 42200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 42300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 42400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 42500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 42600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 42700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 42800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 42900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 43000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 43100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 43200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 43300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 43400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 43500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 43600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 43700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 43800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 43900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 44000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 44100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 44200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 44300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 44400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 44500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 44600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 44700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 44800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 44900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 45000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 45100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 45200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 45300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 45400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 45500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 45600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 45700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 45800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 45900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 46000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 46100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 46200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 46300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 46400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 46500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 46600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 46700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 46800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 46900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 47000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 47100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 47200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 47300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 47400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 47500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 47600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 47700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 47800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 47900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 48000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 48100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 48200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 48300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 48400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 48500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 48600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 48700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 48800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 48900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 49000\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 49100\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 49200\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 49300\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 49400\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 49500\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 49600\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 49700\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 49800\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n",
            "Currently on step 49900\n",
            "Accuracy is:\n",
            "0.07857143\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X9uiFJ-ogBRi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading a Model"
      ]
    },
    {
      "metadata": {
        "id": "dbtjpi8JgBRj",
        "colab_type": "code",
        "outputId": "c959f299-ebd1-459b-8f5d-830eb4021a21",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    \n",
        "    # Restore the model\n",
        "    saver.restore(sess, 'models_saving/my_model.ckpt')\n",
        "    \n",
        "\n",
        "    # Fetch Back Results\n",
        "    label = sess.run(y_pred, feed_dict={x:X_unlabeled,hold_prob:1.0})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from models_saving/my_model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "67eRDYiDgBRm",
        "colab_type": "code",
        "outputId": "072c39fb-512d-4b99-c3f1-5e43583a43e6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "metadata": {
        "id": "9KWKoSzEgBRq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label = np.argmax(label, axis=1 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hCR-AZTmgBRt",
        "colab_type": "code",
        "outputId": "15cd3ce6-3b5d-4d1e-ff47-c470d7594ecf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "metadata": {
        "id": "ojRKNc76gBRx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Predict the unlabeled test sets using the model"
      ]
    },
    {
      "metadata": {
        "id": "yQrGiou8gBRy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imageId = np.arange(1,label.shape[0]+1).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Oj02pY3gBR1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction_pd = pd.DataFrame({'ImageId':imageId, 'Label':label})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VLjMgeXEgBR4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction_pd.to_csv('out_cnn4.csv',sep = ',', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "76xhwmO1gBR6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}